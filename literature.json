[
	{
		"id": "http://zotero.org/users/5814862/items/9DTSCRJT",
		"type": "article-journal",
		"title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
		"abstract": "We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.",
		"URL": "http://arxiv.org/abs/1703.03400",
		"author": [
			{
				"family": "Finn",
				"given": "Chelsea"
			},
			{
				"family": "Abbeel",
				"given": "Pieter"
			},
			{
				"family": "Levine",
				"given": "Sergey"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2017",
					3
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/5814862/items/DAXZBBKD",
		"type": "paper-conference",
		"title": "Understanding Data Augmentation for Classification: When to Warp?",
		"container-title": "2016 International Conference on Digital Image Computing: Techniques and Applications, DICTA 2016",
		"publisher": "Institute of Electrical and Electronics Engineers Inc.",
		"abstract": "In this paper we investigate the benefit of augmenting data with synthetically created samples when training a machine learning classifier. Two approaches for creating additional training samples are data warping, which generates additional samples through transformations applied in the data-space, and synthetic over-sampling, which creates additional samples in feature-space. We experimentally evaluate the benefits of data augmentation for a convolutional backpropagation-trained neural network, a convolutional support vector machine and a convolutional extreme learning machine classifier, using the standard MNIST handwritten digit dataset. We found that while it is possible to perform generic augmentation in feature-space, if plausible transforms for the data are known then augmentation in data-space provides a greater benefit for improving performance and reducing overfitting.",
		"DOI": "10.1109/DICTA.2016.7797091",
		"ISBN": "978-1-5090-2896-2",
		"author": [
			{
				"family": "Wong",
				"given": "Sebastien C."
			},
			{
				"family": "Gatt",
				"given": "Adam"
			},
			{
				"family": "Stamatescu",
				"given": "Victor"
			},
			{
				"family": "McDonnell",
				"given": "Mark D."
			}
		],
		"issued": {
			"date-parts": [
				[
					"2016",
					12
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/5814862/items/ABPNQ7YI",
		"type": "article-journal",
		"title": "Cats or CAT scans: transfer learning from natural or medical image source datasets?",
		"abstract": "Transfer learning is a widely used strategy in medical image analysis. Instead of only training a network with a limited amount of data from the target task of interest, we can first train the network with other, potentially larger source datasets, creating a more robust model. The source datasets do not have to be related to the target task. For a classification task in lung CT images, we could use both head CT images, or images of cats, as the source. While head CT images appear more similar to lung CT images, the number and diversity of cat images might lead to a better model overall. In this survey we review a number of papers that have performed similar comparisons. Although the answer to which strategy is best seems to be \"it depends\", we discuss a number of research directions we need to take as a community, to gain more understanding of this topic.",
		"URL": "http://arxiv.org/abs/1810.05444 http://dx.doi.org/10.1016/j.cobme.2018.12.005",
		"DOI": "10.1016/j.cobme.2018.12.005",
		"author": [
			{
				"family": "Cheplygina",
				"given": "Veronika"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2018",
					10
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/5814862/items/J7KI366G",
		"type": "book",
		"title": "Statistical reinforcement learning: Modern machine learning approaches",
		"publisher": "CRC Press",
		"number-of-pages": "1–191",
		"abstract": "Reinforcement learning is a mathematical framework for developing computer agents that can learn an optimal behavior by relating generic reward signals with its past actions. With numerous successful applications in business intelligence, plant control, and gaming, the RL framework is ideal for decision making in unknown environments with large amounts of data.Supplying an up-to-date and accessible introduction to the field, Statistical Reinforcement Learning: Modern Machine Learning Approaches presents fundamental concepts and practical algorithms of statistical reinforcement learning from th. Cover; Contents; Foreword; Preface; Author; Part I: Introduction; Chapter 1: Introduction to Reinforcement Learning; Part II: Model-Free Policy Iteration; Chapter 2: Policy Iteration with Value Function Approximation; Chapter 3: Basis Design for Value Function Approximation; Chapter 4: Sample Reuse in Policy Iteration; Chapter 5: Active Learning in Policy Iteration; Chapter 6: Robust Policy Iteration; Part III: Model-Free Policy Search; Chapter 7: Direct Policy Search by Gradient Ascent; Chapter 8: Direct Policy Search by Expectation-Maximization; Chapter 9: Policy-Prior Search Part IV: Model-Based Reinforcement LearningChapter 10: Transition Model Estimation; Chapter 11: Dimensionality Reduction for Transition Model Estimation; References",
		"ISBN": "978-1-4398-5690-1",
		"note": "DOI: 10.1201/b18188",
		"author": [
			{
				"family": "Sugiyama",
				"given": "Masashi"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2015",
					1
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/5814862/items/S39MGJVI",
		"type": "paper-conference",
		"title": "On the impact of data set size in transfer learning using deep neural networks",
		"container-title": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
		"publisher": "Springer Verlag",
		"page": "50–60",
		"volume": "9897 LNCS",
		"abstract": "In this we paper we study the effect of target set size on transfer learning in deep learning convolutional neural networks. This is an important problem as labelling is a costly task, or for new or specific classes the number of labelled instances available may simply be too small. We present results for a series of experiments where we either train on a target of classes from scratch, retrain all layers, or subsequently lock more layers in the network, for the Tiny-ImageNet and MiniPlaces2 data sets. Our findings indicate that for smaller target data sets freezing the weights for the initial layers of the network gives better results on the target set classes. We present a simple and easy to implement training heuristic based on these findings.",
		"DOI": "10.1007/978-3-319-46349-0_5",
		"ISBN": "978-3-319-46348-3",
		"author": [
			{
				"family": "Soekhoe",
				"given": "Deepak"
			},
			{
				"family": "Putten",
				"given": "Peter",
				"non-dropping-particle": "van der"
			},
			{
				"family": "Plaat",
				"given": "Aske"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2016"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/5814862/items/RBFE7WMK",
		"type": "report",
		"title": "Meta-Learning for Medical Image Classification",
		"abstract": "Most of the current state-of-the-art methods to classify medical images is to first train a deep model on ImageNet, then transfer all network weights to a new network except for the last softmax layer, and then fine-tune on the target dataset. When the amount of training data in the target dataset is sufficient, this method is able to surpass the level of a trained doctor on several datasets; however, when it is insufficient, which is common in a lot of real medical applications, this method may lead to mediocre results. To address the small dataset problem, we apply a meta-learning method to train, and then fine-tune on the target dataset. We show our results surpass the state-of-the-art method on a popular medical image dataset.",
		"URL": "https://www.kaggle.com/c/",
		"author": [
			{
				"family": "Hu",
				"given": "Shi"
			},
			{
				"family": "Tomczak",
				"given": "Jakub"
			},
			{
				"family": "Welling",
				"given": "Max"
			}
		]
	},
	{
		"id": "http://zotero.org/users/5814862/items/XNB3NN7X",
		"type": "article-journal",
		"title": "Discovery Science",
		"volume": "2534",
		"issue": "May 2014",
		"URL": "http://link.springer.com/10.1007/3-540-36182-0",
		"DOI": "10.1007/3-540-36182-0",
		"author": [
			{
				"family": "Peng",
				"given": "Yonghong"
			},
			{
				"family": "Flach",
				"given": "Peter A"
			},
			{
				"family": "Soares",
				"given": "Carlos"
			},
			{
				"family": "Brazdil",
				"given": "Pavel"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2002"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/5814862/items/747SEG44",
		"type": "article-journal",
		"title": "Metalearning: a survey of trends and technologies",
		"container-title": "Artificial Intelligence Review",
		"page": "117–130",
		"volume": "44",
		"issue": "1",
		"abstract": "© 2013, The Author(s). Metalearning attracted considerable interest in the machine learning community in the last years. Yet, some disagreement remains on what does or what does not constitute a metalearning problem and in which contexts the term is used in. This survey aims at giving an all-encompassing overview of the research directions pursued under the umbrella of metalearning, reconciling different definitions given in scientific literature, listing the choices involved when designing a metalearning system and identifying some of the future research challenges in this domain.",
		"DOI": "10.1007/s10462-013-9406-y",
		"ISSN": "15737462",
		"author": [
			{
				"family": "Lemke",
				"given": "Christiane"
			},
			{
				"family": "Budka",
				"given": "Marcin"
			},
			{
				"family": "Gabrys",
				"given": "Bogdan"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2015"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/5814862/items/S6WS8N9Y",
		"type": "article-journal",
		"title": "Meta-Learning: A Survey",
		"page": "1–29",
		"abstract": "Meta-learning, or learning to learn, is the science of systematically observing how different machine learning approaches perform on a wide range of learning tasks, and then learning from this experience, or meta-data, to learn new tasks much faster than otherwise possible. Not only does this dramatically speed up and improve the design of machine learning pipelines or neural architectures, it also allows us to replace hand-engineered algorithms with novel approaches learned in a data-driven way. In this chapter, we provide an overview of the state of the art in this fascinating and continuously evolving field.",
		"URL": "http://arxiv.org/abs/1810.03548",
		"author": [
			{
				"family": "Vanschoren",
				"given": "Joaquin"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2018"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/5814862/items/Z4HEEZ8R",
		"type": "paper-conference",
		"title": "Exploring the Similarity of Medical Imaging Classification Problems",
		"container-title": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
		"publisher": "Springer Verlag",
		"page": "59–66",
		"volume": "10552 LNCS",
		"abstract": "Supervised learning is ubiquitous in medical image analysis. In this paper we consider the problem of meta-learning – predicting which methods will perform well in an unseen classification problem, given previous experience with other classification problems. We investigate the first step of such an approach: how to quantify the similarity of different classification problems. We characterize datasets sampled from six classification problems by performance ranks of simple classifiers, and define the similarity by the inverse of Euclidean distance in this meta-feature space. We visualize the similarities in a 2D space, where meaningful clusters start to emerge, and show that the proposed representation can be used to classify datasets according to their origin with 89.3$\\backslash$% accuracy. These findings, together with the observations of recent trends in machine learning, suggest that meta-learning could be a valuable tool for the medical imaging community.",
		"DOI": "10.1007/978-3-319-67534-3_7",
		"ISBN": "978-3-319-67533-6",
		"author": [
			{
				"family": "Cheplygina",
				"given": "Veronika"
			},
			{
				"family": "Moeskops",
				"given": "Pim"
			},
			{
				"family": "Veta",
				"given": "Mitko"
			},
			{
				"family": "Dashtbozorg",
				"given": "Behdad"
			},
			{
				"family": "Pluim",
				"given": "Josien P.W."
			}
		],
		"issued": {
			"date-parts": [
				[
					"2017"
				]
			]
		}
	}
]